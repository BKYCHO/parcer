import requests
from bs4 import BeautifulSoup as BS
import re


# Без юзерагента сайт дает ошибку 404

def get_html(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}
    r = requests.get(url, headers=headers)
    return r.text

# Поиск максимального количества страниц в запросе

def get_total_pages(html):
    soup = BS(html, 'lxml')
    pages = soup.find_all('a', class_='bloko-button HH-Pager-Control')[-1].get('data-page')
    return int(pages)

def get_page_links(html):
    soup = BS(html, 'lxml')
    links = soup.find('div', class_='vacancy-serp').find_all('a', class_='bloko-link HH-LinkModifier')
    all_links = []
    for link in links:
        url = link.get('href')
        all_links.append(url)
    return all_links





def main():
    url = 'https://spb.hh.ru/search/vacancy?L_is_autosearch=false&area=2&clusters=true&enable_snippets=true&text=Python&page=1'
    base_url = 'https://spb.hh.ru/search/vacancy?L_is_autosearch=false&area=2&clusters=true&enable_snippets=true&text='
    page_part = '&page='
    query_part = 'Python'

    pages = get_total_pages(get_html(url))

    for page_number in range(0, 3): # Вторым значением потом поставить pages+1
        url_full = base_url + query_part + page_part + str(page_number)
        #print(url_full)
        html = get_html(url_full)
        print(get_page_links(html))




if __name__ == "__main__":
    main()